# Summarizarr Environment Configuration
# Copy this file to .env and configure your settings

# ============================================================================
# REQUIRED CONFIGURATION
# ============================================================================

# Signal phone number (required)
# Format: +1234567890
SIGNAL_PHONE_NUMBER=+1234567890

# AI Provider Selection (required)
# Options: local, openai, groq, gemini, claude
AI_PROVIDER=openai

# ============================================================================
# AI PROVIDER CONFIGURATIONS
# ============================================================================

# OpenAI Configuration (when AI_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Groq Configuration (when AI_PROVIDER=groq)
GROQ_API_KEY=your-groq-api-key-here
GROQ_MODEL=llama-3.1-8b-instant
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Gemini Configuration (when AI_PROVIDER=gemini)
# Note: Requires OpenAI-compatible proxy
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-pro
GEMINI_BASE_URL=https://your-gemini-proxy.com/v1

# Claude Configuration (when AI_PROVIDER=claude)
# Note: Requires OpenAI-compatible proxy
CLAUDE_API_KEY=your-claude-api-key-here
CLAUDE_MODEL=claude-3-haiku-20240307
CLAUDE_BASE_URL=https://your-claude-proxy.com/v1

# Local AI Configuration (when AI_PROVIDER=local)
# Requires Ollama running as sidecar service. Quick setup:
# docker run -d -p 11434:11434 --name ollama ollama/ollama
# docker exec ollama ollama pull llama3.2:1b
LOCAL_MODEL=llama3.2:1b
OLLAMA_HOST=http://localhost:11434
OLLAMA_KEEP_ALIVE=5m

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

# How often to generate summaries
# Examples: 30m, 1h, 2h, 6h, 12h, 24h
SUMMARIZATION_INTERVAL=1h

# Database path (for container deployment, leave as default)
DATABASE_PATH=/data/summarizarr.db

# Signal CLI URL (for container deployment, leave as default)
SIGNAL_URL=http://signal-cli:8080

# Logging level
# Options: debug, info, warn, error
LOG_LEVEL=info

# ============================================================================
# AUTHENTICATION SETTINGS
# ============================================================================

# Better Auth Configuration (automatically generated secrets work for development)
# For production, set a strong random secret (32+ characters)
# BETTER_AUTH_SECRET=your-super-secure-random-32-character-secret-here

# Better Auth URL (should match your deployment URL)
# Development: http://localhost:3000 (frontend dev server)
# Production: http://localhost:8081 (single binary)
BETTER_AUTH_URL=http://localhost:8081

# ============================================================================
# DEVELOPMENT SETTINGS (optional)
# ============================================================================

# Enable debug mode
# DEBUG=true

# Ollama keep-alive duration (how long to keep models loaded)
# OLLAMA_KEEP_ALIVE=5m

# Custom configuration path
# CONFIG_PATH=/config

# ============================================================================
# DOCKER COMPOSE PROFILES
# ============================================================================

# Uncomment to enable specific profiles
# COMPOSE_PROFILES=development
# COMPOSE_PROFILES=production
