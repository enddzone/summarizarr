# Example environment variables for Summarizarr
# Copy this file to .env and fill in your actual values

# Required: Signal phone number (with country code, e.g., +1234567890)
SIGNAL_PHONE_NUMBER=+1234567890

# Optional: How often to generate summaries (default: 12h)
# Examples: 30m, 1h, 6h, 12h, 24h
SUMMARIZATION_INTERVAL=12h

# Optional: AI backend ('local' for Ollama, 'openai' for OpenAI)
AI_BACKEND=local

# --- Local AI (Ollama) Settings ---
# Optional: Local AI model to use (default: llama3.2:1b)
# Supported: llama3.2:1b, phi3, llama2, mistral, codellama
LOCAL_MODEL=llama3.2:1b

# Optional: Automatically download and start Ollama (default: true)
OLLAMA_AUTO_DOWNLOAD=true

# Optional: Ollama server host and port (default: 127.0.0.1:11434)
OLLAMA_HOST=127.0.0.1:11434

# Optional: How long to keep models in memory (default: 5m)
OLLAMA_KEEP_ALIVE=5m

# --- OpenAI Settings (required when AI_BACKEND=openai) ---
# OpenAI API key - get from https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-api-key-here

# Optional: OpenAI model to use (default: gpt-4o)
# Supported: gpt-4o, gpt-4, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o

# --- General Settings ---
# Optional: Directory to store AI models (default: ./models)
# For Docker: /app/models
MODELS_PATH=./models

# Optional: Log level (default: INFO)
# Options: DEBUG, INFO, WARN, ERROR
LOG_LEVEL=INFO

# Optional: Database path (default: summarizarr.db)
# For Docker: /app/data/summarizarr.db
DATABASE_PATH=summarizarr.db
