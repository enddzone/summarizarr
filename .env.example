# Example environment variables for Summarizarr
# Copy this file to .env and fill in your actual values

# Required: Signal phone number (with country code, e.g., +1234567890)
SIGNAL_PHONE_NUMBER=+1234567890

# Optional: How often to generate summaries (default: 12h)
# Examples: 30m, 1h, 6h, 12h, 24h
SUMMARIZATION_INTERVAL=12h

# Optional: AI backend (only 'local' is supported)
AI_BACKEND=local

# Optional: Local AI model to use (default: phi3)
# Supported: phi3, llama2, mistral, codellama
LOCAL_MODEL=phi3

# Optional: Automatically download and start Ollama (default: true)
OLLAMA_AUTO_DOWNLOAD=true

# Optional: Ollama server host and port (default: 127.0.0.1:11434)
OLLAMA_HOST=127.0.0.1:11434

# Optional: How long to keep models in memory (default: 5m)
OLLAMA_KEEP_ALIVE=5m

# Optional: Directory to store AI models (default: ./models)
# For Docker: /app/models
MODELS_PATH=./models

# Optional: Log level (default: INFO)
# Options: DEBUG, INFO, WARN, ERROR
LOG_LEVEL=INFO

# Optional: Database path (default: summarizarr.db)
# For Docker: /app/data/summarizarr.db
DATABASE_PATH=summarizarr.db
