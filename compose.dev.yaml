# Docker Compose configuration for Summarizarr Development
# Complete development stack with local builds and directory mounts

services:
  signal-cli:
    image: bbernhard/signal-cli-rest-api:latest
    container_name: signal-cli-dev
    environment:
      - MODE=json-rpc
    ports:
      - "8080:8080"
    volumes:
      # Mount local directory for easy access to Signal CLI config
      - ./signal-cli-config:/home/.local/share/signal-cli
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/about"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - summarizarr-dev-network

  summarizarr:
    # Build from local Dockerfile for development
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VERSION: dev
        GIT_COMMIT: dev
        BUILD_TIME: dev
        GOARCH: ${GOARCH:-arm64}
    image: summarizarr:dev
    container_name: summarizarr-dev
    environment:
      # Required Configuration
      - SIGNAL_PHONE_NUMBER=${SIGNAL_PHONE_NUMBER}
      - AI_PROVIDER=${AI_PROVIDER:-local}

      # AI Provider Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.1-8b-instant}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-pro}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-haiku-20240307}

      # Local AI (Ollama) Configuration - for sidecar usage only
      - LOCAL_MODEL=${LOCAL_MODEL:-llama3.2:1b}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama-dev:11434}

      # Application Configuration
      - SUMMARIZATION_INTERVAL=${SUMMARIZATION_INTERVAL:-1h}
      - DATABASE_PATH=/data/summarizarr.db
      - SIGNAL_URL=signal-cli:8080
      - LOG_LEVEL=debug # Debug level for development
    ports:
      - "8081:8080" # Unified API + frontend
    volumes:
      # Mount local directories for easy development access
      - ./data:/data
      - ./config:/config
    depends_on:
      signal-cli:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - summarizarr-dev-network

  # Ollama service for local AI processing (sidecar mode)
  # Enabled for testing local AI workflow
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-dev
    ports:
      - "11434:11434"
    volumes:
      # Mount local directory for model persistence
      - ./ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - summarizarr-dev-network
    # GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]

  # Development database viewer
  adminer:
    image: adminer:latest
    container_name: adminer-dev
    ports:
      - "8083:8080"
    environment:
      - ADMINER_DEFAULT_SERVER=summarizarr-dev
    depends_on:
      - summarizarr
    networks:
      - summarizarr-dev-network
    restart: unless-stopped

  # Development log viewer
  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle-dev
    ports:
      - "8084:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - summarizarr-dev-network
    restart: unless-stopped

networks:
  summarizarr-dev-network:
    driver: bridge

