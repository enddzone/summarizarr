# Docker Compose configuration for Summarizarr
# Production-ready example setup using pre-built images
#
# IMPORTANT: This configuration uses Docker named volumes for data persistence.
# For production use, you MUST mount local directories to persist data beyond container restarts:
#
# Replace the volumes section with local directory mounts:
#   volumes:
#     - ./data:/data                                          # Database and application data
#     - ./signal-cli-config:/home/.local/share/signal-cli     # Signal CLI configuration
#
# Without local directory mounts, ALL DATA WILL BE LOST when containers are removed!

services:
  signal-cli:
    image: bbernhard/signal-cli-rest-api:latest
    container_name: signal-cli
    environment:
      - MODE=json-rpc
    ports:
      - "8080:8080"
    volumes:
      # WARNING: Using named volume - data will be lost if container is removed
      # For production: mount local directory instead: ./signal-cli-config:/home/.local/share/signal-cli
      # - ./signal-cli-config:/home/.local/share/signal-cli
      - signal-cli-config:/home/.local/share/signal-cli
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/about"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - summarizarr-network

  summarizarr:
    image: ghcr.io/enddzone/summarizarr:latest
    container_name: summarizarr
    environment:
      # Required Configuration
      - SIGNAL_PHONE_NUMBER=${SIGNAL_PHONE_NUMBER}
      - AI_PROVIDER=${AI_PROVIDER:-openai}

      # AI Provider Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.1-8b-instant}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-pro}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-haiku-20240307}

      # Local AI (Ollama) Configuration - for sidecar usage only
      - LOCAL_MODEL=${LOCAL_MODEL:-llama3.2:1b}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-5m}

      # Application Configuration
      - SUMMARIZATION_INTERVAL=${SUMMARIZATION_INTERVAL:-1h}
      - DATABASE_PATH=/data/summarizarr.db
      - SIGNAL_URL=signal-cli:8080
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Authentication Configuration
      - BETTER_AUTH_SECRET=${BETTER_AUTH_SECRET:-}
      - BETTER_AUTH_URL=${BETTER_AUTH_URL:-http://localhost:8081}
    ports:
      - "8081:8080" # Unified API + frontend
    volumes:
      # WARNING: Using named volumes - data will be lost if containers are removed
      # For production: mount local directories instead:
      # - ./data:/data
      # - ./config:/config
      - summarizarr-data:/data
      - summarizarr-config:/config
    depends_on:
      signal-cli:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - summarizarr-network

  # Ollama service for local AI processing (sidecar mode)
  # Uncomment this service when using AI_PROVIDER=local with Ollama sidecar
  # Remember to change OLLAMA_HOST to 'http://ollama:11434' in the environment section above
  #
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     # For production: mount local directory instead: ./ollama-data:/root/.ollama
  #     - ollama-data:/root/.ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #   restart: unless-stopped
  #   networks:
  #     - summarizarr-network
  #   # GPU support (uncomment if you have NVIDIA GPU)
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]
  #   profiles:
  #     - local-ai

networks:
  summarizarr-network:
    driver: bridge

volumes:
  # WARNING: These named volumes will lose data when containers are removed!
  # For production deployments, replace these with local directory mounts:
  #
  # Instead of named volumes, use:
  #   volumes:
  #     - ./data:/data
  #     - ./signal-cli-config:/home/.local/share/signal-cli
  #     - ./config:/config
  #     # - ./ollama-data:/root/.ollama  # if using ollama sidecar service
  signal-cli-config:
    driver: local
  summarizarr-data:
    driver: local
  summarizarr-config:
    driver: local
  # ollama-data:  # Uncomment if using Ollama sidecar service
  #   driver: local

