# Docker Compose configuration for Summarizarr
# Production-ready example setup using pre-built images
#
# IMPORTANT: This configuration uses Docker named volumes for data persistence.
# For production use, you MUST mount local directories to persist data beyond container restarts:
#
# Replace the volumes section with local directory mounts:
#   volumes:
#     - ./data:/data                                          # Database and application data
#     - ./signal-cli-config:/home/.local/share/signal-cli     # Signal CLI configuration
#
# Without local directory mounts, ALL DATA WILL BE LOST when containers are removed!

services:
  signal-cli:
    image: bbernhard/signal-cli-rest-api:latest
    container_name: signal-cli
    environment:
      - MODE=json-rpc
    ports:
      - "8080:8080"
    volumes:
      # WARNING: Using named volume - data will be lost if container is removed
      # For production: mount local directory instead: ./signal-cli-config:/home/.local/share/signal-cli
      - signal-cli-config:/home/.local/share/signal-cli
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/about"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - summarizarr-network

  summarizarr:
    image: ghcr.io/enddzone/summarizarr:latest
    container_name: summarizarr
    environment:
      # Required Configuration
      - SIGNAL_PHONE_NUMBER=${SIGNAL_PHONE_NUMBER}
      - AI_PROVIDER=${AI_PROVIDER:-local}
      
      # AI Provider Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.1-8b-instant}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-pro}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
      - CLAUDE_MODEL=${CLAUDE_MODEL:-claude-3-haiku-20240307}
      
      # Local AI (Ollama) Configuration
      - LOCAL_MODEL=${LOCAL_MODEL:-llama3.2:1b}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://localhost:11434}
      - OLLAMA_AUTO_DOWNLOAD=${OLLAMA_AUTO_DOWNLOAD:-true}
      
      # Application Configuration
      - SUMMARIZATION_INTERVAL=${SUMMARIZATION_INTERVAL:-1h}
      - DATABASE_PATH=/data/summarizarr.db
      - SIGNAL_URL=signal-cli:8080
      - LOG_LEVEL=${LOG_LEVEL:-info}
    ports:
      - "8081:8080"
    volumes:
      # WARNING: Using named volumes - data will be lost if containers are removed
      # For production: mount local directories instead:
      #   - ./data:/data
      #   - ./config:/config
      - summarizarr-data:/data
      - summarizarr-config:/config
    depends_on:
      signal-cli:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - summarizarr-network

  # Optional: Ollama service for local AI processing
  # Uncomment the section below if you want to run Ollama in a separate container
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     # WARNING: Using named volume - models will be lost if container is removed
  #     # For production: mount local directory instead: ./ollama-data:/root/.ollama
  #     - ollama-data:/root/.ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #   restart: unless-stopped
  #   networks:
  #     - summarizarr-network
  #   # GPU support (uncomment if you have NVIDIA GPU)
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]

networks:
  summarizarr-network:
    driver: bridge

volumes:
  # WARNING: These named volumes will lose data when containers are removed!
  # For production deployments, replace these with local directory mounts:
  #
  # Instead of named volumes, use:
  #   volumes:
  #     - ./data:/data
  #     - ./signal-cli-config:/home/.local/share/signal-cli
  #     - ./config:/config
  #     # - ./ollama-data:/root/.ollama  # if using ollama service
  signal-cli-config:
    driver: local
  summarizarr-data:
    driver: local
  summarizarr-config:
    driver: local
  # ollama-data:
  #   driver: local